{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mesm\u001b[39;00m \n\u001b[0;32m      3\u001b[0m esm2, esm2_alphabet \u001b[38;5;241m=\u001b[39m esm\u001b[38;5;241m.\u001b[39mpretrained\u001b[38;5;241m.\u001b[39mesm2_t33_650M_UR50D()\n\u001b[1;32m----> 4\u001b[0m esm2 \u001b[38;5;241m=\u001b[39m \u001b[43mesm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m esm2_batch_converter \u001b[38;5;241m=\u001b[39m esm2_alphabet\u001b[38;5;241m.\u001b[39mget_batch_converter()\n",
      "File \u001b[1;32mc:\\Users\\piotr\\anaconda3\\envs\\esm_note_3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piotr\\anaconda3\\envs\\esm_note_3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piotr\\anaconda3\\envs\\esm_note_3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piotr\\anaconda3\\envs\\esm_note_3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\piotr\\anaconda3\\envs\\esm_note_3\\Lib\\site-packages\\torch\\cuda\\__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import esm \n",
    "\n",
    "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "esm2 = esm2.eval().cuda()\n",
    "esm2_batch_converter = esm2_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x28677571820>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
    "import itertools\n",
    "import os\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from Bio import SeqIO\n",
    "#import biotite.structure as bs\n",
    "#from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
    "#from biotite.database import rcsb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import esm\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2_predictions = {}\n",
    "esm2_results = []\n",
    "for name, inputs in sequences.items():\n",
    "    esm2_batch_labels, esm2_batch_strs, esm2_batch_tokens = esm2_batch_converter([inputs])\n",
    "    esm2_batch_tokens = esm2_batch_tokens.to(next(esm2.parameters()).device)\n",
    "    esm2_predictions[name] = esm2.predict_contacts(esm2_batch_tokens)[0].cpu()\n",
    "    metrics = {\"id\": name, \"model\": \"ESM-2 (Unsupervised)\"}\n",
    "    metrics.update(evaluate_prediction(esm2_predictions[name], contacts[name]))\n",
    "    esm2_results.append(metrics)\n",
    "esm2_results = pd.DataFrame(esm2_results)\n",
    "display(esm2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n",
    "def plot_contacts_and_predictions(\n",
    "    predictions: Union[torch.Tensor, np.ndarray],\n",
    "    contacts: Union[torch.Tensor, np.ndarray],\n",
    "    ax: Optional[mpl.axes.Axes] = None,\n",
    "    # artists: Optional[ContactAndPredictionArtists] = None,\n",
    "    cmap: str = \"Blues\",\n",
    "    ms: float = 1,\n",
    "    title: Union[bool, str, Callable[[float], str]] = True,\n",
    "    animated: bool = False,\n",
    ") -> None:\n",
    "\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "    if isinstance(contacts, torch.Tensor):\n",
    "        contacts = contacts.detach().cpu().numpy()\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    seqlen = contacts.shape[0]\n",
    "    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n",
    "    bottom_mask = relative_distance < 0\n",
    "    masked_image = np.ma.masked_where(bottom_mask, predictions)\n",
    "    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n",
    "    predictions = predictions.copy()\n",
    "    predictions[invalid_mask] = float(\"-inf\")\n",
    "\n",
    "    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n",
    "    pred_contacts = predictions >= topl_val\n",
    "    true_positives = contacts & pred_contacts & ~bottom_mask\n",
    "    false_positives = ~contacts & pred_contacts & ~bottom_mask\n",
    "    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n",
    "\n",
    "    if isinstance(title, str):\n",
    "        title_text: Optional[str] = title\n",
    "    elif title:\n",
    "        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n",
    "            \"P@L\"\n",
    "        ].item()\n",
    "        if callable(title):\n",
    "            title_text = title(long_range_pl)\n",
    "        else:\n",
    "            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n",
    "    else:\n",
    "        title_text = None\n",
    "\n",
    "    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n",
    "    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n",
    "    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n",
    "    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n",
    "    ti = ax.set_title(title_text) if title_text is not None else None\n",
    "    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n",
    "\n",
    "    ax.axis(\"square\")\n",
    "    ax.set_xlim([0, seqlen])\n",
    "    ax.set_ylim([0, seqlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(18, 6), ncols=3)\n",
    "for ax, name in zip(axes, PDB_IDS):\n",
    "    prediction = esm2_predictions[name]\n",
    "    target = contacts[name]\n",
    "    plot_contacts_and_predictions(\n",
    "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
    "    )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_note_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
